{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "不可能，絕對不可能！\n",
    "\n",
    "統計一下母體之後丟上去！\n",
    "\n",
    "分數就有 0.55569 了！\n",
    "\n",
    "太離譜了！太離譜辣！"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "206feb76fb7fd74b"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-01T14:04:01.264063Z",
     "start_time": "2024-01-01T14:03:58.996873Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# index, session_id, song_id, unix_played_at, play_status, login_type, listening_order\n",
    "test_source = pd.read_parquet(\"../../datagame-2023/label_test_source.parquet\")\n",
    "# index, song_id, artist_id, song_length, album_id, language_id, album_month\n",
    "meta_song = pd.read_parquet(\"../../datagame-2023/meta_song.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "test_session_to_songs = test_source.groupby('session_id')['song_id'].apply(list).to_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T14:04:05.074905Z",
     "start_time": "2024-01-01T14:04:01.279972Z"
    }
   },
   "id": "f53341f068d25819"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1030712/1030712 [00:03<00:00, 313915.60it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "song_to_artist = dict()\n",
    "song_to_album = dict()\n",
    "\n",
    "for row in tqdm(meta_song.itertuples(), total=len(meta_song)):\n",
    "    if not pd.isna(row.artist_id):\n",
    "        song_to_artist[row.song_id] = int(row.artist_id)\n",
    "\n",
    "    if not pd.isna(row.album_id):\n",
    "        song_to_album[row.song_id] = int(row.album_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T14:04:08.406971Z",
     "start_time": "2024-01-01T14:04:05.076145Z"
    }
   },
   "id": "db13c92e788c514"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "del test_source, meta_song"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T14:04:08.482664Z",
     "start_time": "2024-01-01T14:04:08.478048Z"
    }
   },
   "id": "992dc29ccb68e9ff"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "class myConditionalFreqDist:\n",
    "    def __init__(self):\n",
    "        self._data = {}\n",
    "        self.values = [1, 0.63, 0.5, 0.43, 0.38]  # ndcg 的加權分數\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self._data.get(key, {})\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        self._data[key] = value\n",
    "\n",
    "    def inc(self, condition, sample, index):\n",
    "        if condition in self._data:\n",
    "            if sample in self._data[condition]:\n",
    "                self._data[condition][sample] += self.values[index]\n",
    "            else:\n",
    "                self._data[condition][sample] = self.values[index]\n",
    "        else:\n",
    "            self._data[condition] = {sample: self.values[index]}\n",
    "\n",
    "    def most_common(self, condition, n=None):\n",
    "        if condition in self._data:\n",
    "            counter = Counter(self._data[condition])\n",
    "            return counter.most_common(n)\n",
    "        else:\n",
    "            return []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T14:04:08.500277Z",
     "start_time": "2024-01-01T14:04:08.496773Z"
    }
   },
   "id": "58214baff5e6f084"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T14:04:08.511757Z",
     "start_time": "2024-01-01T14:04:08.501527Z"
    }
   },
   "id": "96f92576325b6529"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "with open('cfd_3grams_test', 'rb') as file:\n",
    "    cfd_3grams = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T14:04:31.597461Z",
     "start_time": "2024-01-01T14:04:08.509717Z"
    }
   },
   "id": "c959a85d3d7b6792"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "with open('cfd_4grams_test', 'rb') as file:\n",
    "    cfd_4grams = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T14:04:57.703879Z",
     "start_time": "2024-01-01T14:04:31.600798Z"
    }
   },
   "id": "38e88772c3a830bf"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "with open('cfd_5grams_test', 'rb') as file:\n",
    "    cfd_5grams = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T14:05:26.187790Z",
     "start_time": "2024-01-01T14:04:57.705801Z"
    }
   },
   "id": "5ad95d91da2faf44"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143064/143064 [00:47<00:00, 3027.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "submit_rows = []\n",
    "results_index = 0\n",
    "part_repeated = 0\n",
    "part4321 = 0\n",
    "part321 = 0\n",
    "part21 = 0\n",
    "part5432 = 0\n",
    "part432 = 0\n",
    "part6543 = 0\n",
    "part543 = 0\n",
    "part32 = 0\n",
    "part321new1 = 0\n",
    "part21new1 = 0\n",
    "part21new1new2 = 0\n",
    "part1new1new2 = 0\n",
    "part_mle = 0\n",
    "same_song_count = 0\n",
    "\n",
    "for key in tqdm(test_session_to_songs.keys(), total=len(test_session_to_songs.keys())):\n",
    "    query_song = test_session_to_songs[key][:]\n",
    "\n",
    "    # 預測下一首歌曲\n",
    "    predicted_songs = []\n",
    "\n",
    "    '''\n",
    "    用戶行為\n",
    "    '''\n",
    "    user_code = 0  # 0=正常用戶，1=單一藝人循環，2=單一專輯循環\n",
    "\n",
    "    is_same_artist = True\n",
    "    is_same_album = True\n",
    "    artist = song_to_artist.get(query_song[-10], '')\n",
    "    album = song_to_album.get(query_song[-10], '')\n",
    "    for query in query_song[-10:]:\n",
    "        if song_to_artist.get(query, ' ') != artist:\n",
    "            is_same_artist = False\n",
    "        if song_to_album.get(query, ' ') != album:\n",
    "            is_same_album = False\n",
    "    if is_same_artist:\n",
    "        user_code = 1\n",
    "    if is_same_album:\n",
    "        user_code = 2\n",
    "\n",
    "    if len(set(query_song[-2:])) == 1:  # 如果倒數兩首都是重複同一首歌\n",
    "        predicted_songs.append(query_song[-1])\n",
    "        part_repeated += 1\n",
    "\n",
    "    is_same_song = False\n",
    "    if len(set(query_song)) < 16:\n",
    "        is_same_song = True  # 可能會聽前面的歌的用戶\n",
    "\n",
    "    '''\n",
    "    5 4 3 grams 依次過濾，分數主要來源來自這三個，其他其實都只是加分項\n",
    "    '''\n",
    "\n",
    "    if len(predicted_songs) < 5:\n",
    "        start_song = (query_song[-4] + query_song[-3] + query_song[-2] + query_song[-1])\n",
    "        next_songs = cfd_5grams.most_common(start_song)\n",
    "\n",
    "        index = 0\n",
    "        while index < len(next_songs) and len(predicted_songs) < 5:\n",
    "            next_song, times = next_songs[index]\n",
    "            index += 1\n",
    "            if next_song not in predicted_songs:\n",
    "                part4321 += 1\n",
    "                predicted_songs.append(next_song)\n",
    "            if len(predicted_songs) >= 5:\n",
    "                break\n",
    "\n",
    "    if len(predicted_songs) < 5:\n",
    "        start_song = (query_song[-3] + query_song[-2] + query_song[-1])\n",
    "        next_songs = cfd_4grams.most_common(start_song)\n",
    "\n",
    "        index = 0\n",
    "        while index < len(next_songs) and len(predicted_songs) < 5:\n",
    "            next_song, times = next_songs[index]\n",
    "            index += 1\n",
    "            if next_song not in predicted_songs:\n",
    "                part321 += 1\n",
    "                predicted_songs.append(next_song)\n",
    "            if len(predicted_songs) >= 5:\n",
    "                break\n",
    "\n",
    "    if len(predicted_songs) < 5:\n",
    "        start_song = (query_song[-2] + query_song[-1])\n",
    "        next_songs = cfd_3grams.most_common(start_song)\n",
    "\n",
    "        index = 0\n",
    "        while index < len(next_songs) and len(predicted_songs) < 5:\n",
    "            next_song, times = next_songs[index]\n",
    "            index += 1\n",
    "            if next_song not in predicted_songs and (next_songs not in query_song or is_same_song):\n",
    "                part21 += 1\n",
    "                predicted_songs.append(next_song)\n",
    "            if len(predicted_songs) >= 5:\n",
    "                break\n",
    "\n",
    "    '''\n",
    "    賭狗行為沒賭到，開始找如果不選 query_song[-1] 的選項\n",
    "    依序是倒數\n",
    "    5432\n",
    "    432\n",
    "    6543\n",
    "    543\n",
    "    32 的預測架構，盡量找長序列，然後加43雖然能找得到東西，但太遠了相關性就掉得厲害\n",
    "    可能可以再改改順序，但算了不凹分\n",
    "    '''\n",
    "    if len(predicted_songs) < 5:\n",
    "        start_song = (query_song[-5] + query_song[-4] + query_song[-3] + query_song[-2])\n",
    "        next_songs = cfd_5grams.most_common(start_song)\n",
    "\n",
    "        index = 0\n",
    "        while index < len(next_songs) and len(predicted_songs) < 5:\n",
    "            next_song, times = next_songs[index]\n",
    "            index += 1\n",
    "            if next_song not in predicted_songs and (next_songs not in query_song or is_same_song):\n",
    "                part5432 += 1\n",
    "                predicted_songs.append(next_song)\n",
    "            if len(predicted_songs) >= 5:\n",
    "                break\n",
    "\n",
    "    if len(predicted_songs) < 5:\n",
    "        start_song = (query_song[-4] + query_song[-3] + query_song[-2])\n",
    "        next_songs = cfd_4grams.most_common(start_song)\n",
    "\n",
    "        index = 0\n",
    "        while index < len(next_songs) and len(predicted_songs) < 5:\n",
    "            next_song, times = next_songs[index]\n",
    "            index += 1\n",
    "            if next_song not in predicted_songs and (next_songs not in query_song or is_same_song):\n",
    "                part432 += 1\n",
    "                predicted_songs.append(next_song)\n",
    "            if len(predicted_songs) >= 5:\n",
    "                break\n",
    "\n",
    "    if len(predicted_songs) < 5:\n",
    "        start_song = (query_song[-6] + query_song[-5] + query_song[-4] + query_song[-3])\n",
    "        next_songs = cfd_5grams.most_common(start_song)\n",
    "\n",
    "        index = 0\n",
    "        while index < len(next_songs) and len(predicted_songs) < 5:\n",
    "            next_song, times = next_songs[index]\n",
    "            index += 1\n",
    "            if next_song not in predicted_songs and (next_songs not in query_song or is_same_song):\n",
    "                part6543 += 1\n",
    "                predicted_songs.append(next_song)\n",
    "            if len(predicted_songs) >= 5:\n",
    "                break\n",
    "\n",
    "    if len(predicted_songs) < 5:\n",
    "        start_song = (query_song[-5] + query_song[-4] + query_song[-3])\n",
    "        next_songs = cfd_4grams.most_common(start_song)\n",
    "\n",
    "        index = 0\n",
    "        while index < len(next_songs) and len(predicted_songs) < 5:\n",
    "            next_song, times = next_songs[index]\n",
    "            index += 1\n",
    "            if next_song not in predicted_songs and (next_songs not in query_song or is_same_song):\n",
    "                part543 += 1\n",
    "                predicted_songs.append(next_song)\n",
    "            if len(predicted_songs) >= 5:\n",
    "                break\n",
    "\n",
    "    if len(predicted_songs) < 5:\n",
    "        start_song = (query_song[-3] + query_song[-2])\n",
    "        next_songs = cfd_3grams.most_common(start_song)\n",
    "\n",
    "        index = 0\n",
    "        while index < len(next_songs) and len(predicted_songs) < 5:\n",
    "            next_song, times = next_songs[index]\n",
    "            index += 1\n",
    "            if next_song not in predicted_songs and (next_songs not in query_song or is_same_song):\n",
    "                part32 += 1\n",
    "                predicted_songs.append(next_song)\n",
    "            if len(predicted_songs) >= 5:\n",
    "                break\n",
    "\n",
    "    '''\n",
    "    賭狗上線\n",
    "    預測順序是 5gram 4gram 先加入第一個變數來預測\n",
    "    接下來是 5gram 4gram 加入第二個變數來預測，因為加入越後面的變數越容易偏掉（可能冷門歌曲亂跳)\n",
    "    加入第三個之後模型預測效能會下降 (0.56056->0.56051)\n",
    "    '''\n",
    "    if 0 < len(predicted_songs) < 5:\n",
    "        for i in range(len(predicted_songs)):\n",
    "            start_song = (query_song[-3] + query_song[-2] + query_song[-1] + predicted_songs[i])\n",
    "            next_songs = cfd_5grams.most_common(start_song)\n",
    "\n",
    "            index = 0\n",
    "            while index < len(next_songs) and len(predicted_songs) < 5:\n",
    "                next_song, times = next_songs[index]\n",
    "                index += 1\n",
    "                if next_song not in predicted_songs and (next_songs not in query_song or is_same_song):\n",
    "                    part321new1 += 1\n",
    "                    predicted_songs.append(next_song)\n",
    "                if len(predicted_songs) >= 5:\n",
    "                    break\n",
    "\n",
    "            if len(predicted_songs) >= 5:\n",
    "                break\n",
    "\n",
    "    if 0 < len(predicted_songs) < 5:\n",
    "        for i in range(len(predicted_songs)):\n",
    "            start_song = (query_song[-2] + query_song[-1] + predicted_songs[i])\n",
    "            next_songs = cfd_4grams.most_common(start_song)\n",
    "\n",
    "            index = 0\n",
    "            while index < len(next_songs) and len(predicted_songs) < 5:\n",
    "                next_song, times = next_songs[index]\n",
    "                index += 1\n",
    "                if next_song not in predicted_songs and (next_songs not in query_song or is_same_song):\n",
    "                    part21new1 += 1\n",
    "                    predicted_songs.append(next_song)\n",
    "                if len(predicted_songs) >= 5:\n",
    "                    break\n",
    "\n",
    "            if len(predicted_songs) >= 5:\n",
    "                break\n",
    "\n",
    "    if 1 < len(predicted_songs) < 5:\n",
    "        for i in range(len(predicted_songs)):\n",
    "            for j in range(len(predicted_songs)):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                start_song = (query_song[-2] + query_song[-1] + predicted_songs[i] + predicted_songs[j])\n",
    "                next_songs = cfd_5grams.most_common(start_song)\n",
    "\n",
    "                index = 0\n",
    "                while index < len(next_songs) and len(predicted_songs) < 5:\n",
    "                    next_song, times = next_songs[index]\n",
    "                    index += 1\n",
    "\n",
    "                    if next_song not in predicted_songs and (next_songs not in query_song or is_same_song):\n",
    "                        part21new1new2 += 1\n",
    "                        predicted_songs.append(next_song)\n",
    "                    if len(predicted_songs) >= 5:\n",
    "                        break\n",
    "\n",
    "                if len(predicted_songs) >= 5:\n",
    "                    break\n",
    "\n",
    "    if 1 < len(predicted_songs) < 5:\n",
    "        for i in range(len(predicted_songs)):\n",
    "            for j in range(len(predicted_songs)):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                start_song = (query_song[-1] + predicted_songs[i] + predicted_songs[j])\n",
    "                next_songs = cfd_4grams.most_common(start_song)\n",
    "\n",
    "                index = 0\n",
    "                while index < len(next_songs) and len(predicted_songs) < 5:\n",
    "                    next_song, times = next_songs[index]\n",
    "                    index += 1\n",
    "\n",
    "                    if next_song not in predicted_songs and (next_songs not in query_song or is_same_song):\n",
    "                        part1new1new2 += 1\n",
    "                        predicted_songs.append(next_song)\n",
    "                    if len(predicted_songs) >= 5:\n",
    "                        break\n",
    "\n",
    "                if len(predicted_songs) >= 5:\n",
    "                    break\n",
    "\n",
    "    '''\n",
    "    pyserini 區域\n",
    "    預計做 MLE and BM25 的混合模型\n",
    "    '''\n",
    "    for i in range(1, 21):\n",
    "        if len(predicted_songs) >= 5:\n",
    "            break\n",
    "        if query_song[-i] not in predicted_songs:\n",
    "            predicted_songs.append(query_song[-i])\n",
    "            same_song_count += 1\n",
    "\n",
    "    if len(predicted_songs) < 5:\n",
    "        predicted_songs.append('18a62aea3e0e67e21ea56c125c29c474')\n",
    "\n",
    "    if len(predicted_songs) < 5:\n",
    "        predicted_songs.append('85422f927d88358292985cb319d216fa')\n",
    "\n",
    "    if len(predicted_songs) < 5:\n",
    "        predicted_songs.append('ef71212934e35b400232a0cd8e7e67a2')\n",
    "\n",
    "    if len(predicted_songs) < 5:\n",
    "        predicted_songs.append('4a27803802d6090389507671d8aed6eb')\n",
    "\n",
    "    if len(predicted_songs) < 5:\n",
    "        predicted_songs.append('bc58d186329eda8b23e510ba98b2c1ea')\n",
    "\n",
    "    # print(\"Predicted Songs:\", predicted_songs)\n",
    "    submit_rows.append([key, *predicted_songs])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T14:10:33.676950Z",
     "start_time": "2024-01-01T14:09:46.256434Z"
    }
   },
   "id": "64495fdef652716"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8327\n",
      "144615 26481 126802\n",
      "86744 3417 80830 2351 32772\n",
      "36 64 24 694 0\n",
      "198779\n"
     ]
    }
   ],
   "source": [
    "# 重複的歌曲\n",
    "print(part_repeated)\n",
    "# 第一層（正統 n gram)\n",
    "print(part4321, part321, part21)\n",
    "# 第二層（擴展 n gram 範圍）\n",
    "print(part5432, part432, part6543, part543, part32)\n",
    "# 第三層（拿預測預測）\n",
    "print(part321new1, part21new1, part21new1new2, part1new1new2, part_mle)\n",
    "print(same_song_count)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T14:10:33.747707Z",
     "start_time": "2024-01-01T14:10:33.675313Z"
    }
   },
   "id": "4ae264f1dfce8a50"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "columns = ['session_id', 'top1', 'top2', 'top3', 'top4', 'top5']\n",
    "output_df = pd.DataFrame(submit_rows, columns=columns)\n",
    "output_df.to_csv('only_ngrams.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T14:08:39.671533Z",
     "start_time": "2024-01-01T14:08:38.442337Z"
    }
   },
   "id": "88c33737513dee8f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-01T14:05:37.337155Z"
    }
   },
   "id": "55d0efc8762f598e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "150299 27066 128429\n",
    "87175 3417 80830 2351 32772\n",
    "3 6 1 633 202159\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T14:05:37.344247Z",
     "start_time": "2024-01-01T14:05:37.343442Z"
    }
   },
   "id": "5a75751b2b646a3c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T14:05:37.416833Z",
     "start_time": "2024-01-01T14:05:37.348069Z"
    }
   },
   "id": "37a121121401b0b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
